<!DOCTYPE html>
<html>

<head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>
        Robin Walters - Research
    </title>

    <!-- Bootstrap & MDB -->
    <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

    <!-- Styles -->
    <link rel="stylesheet" href="../css/main.css">
    <link rel="canonical" href="/">

</head>

<body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->
    <header>
        <!-- Nav Bar -->
        <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
            <div class="container">
                <!-- Logo -->
                <a href="../index.html" class="navbar-brand">
                    <img src="../images/logo.png" alt="Logo" style="height: 60px;"> <!-- Adjust the height as needed -->
                </a>
                <!-- Navbar Toggle -->
                <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar top-bar"></span>
                    <span class="icon-bar middle-bar"></span>
                    <span class="icon-bar bottom-bar"></span>
                </button>
                <div class="collapse navbar-collapse text-right" id="navbarNav">
                    <ul class="navbar-nav ml-auto flex-nowrap">
                        <!-- About -->
                        <li class="nav-item active">
                            <a class="nav-link" href="../index.html">
                                Home              
                                <span class="sr-only">(current)</span>              
                            </a>
                        </li>

                        <li class="nav-item active">
                            <a class="nav-link" href="research.html">
                                Research              
                                <span class="sr-only">(current)</span>              
                            </a>
                        </li>

                        <li class="nav-item active">
                            <a class="nav-link" href="geometric-learning-lab.html">
                                Lab             
                                <span class="sr-only">(current)</span>              
                            </a>
                        </li>

                        <li class="nav-item active">
                            <a class="nav-link" href="teaching.html">
                                Teaching              
                                <span class="sr-only">(current)</span>              
                            </a>
                        </li>

                        <li class="nav-item active">
                            <a class="nav-link" href="photos.html">
                                Photos             
                                <span class="sr-only">(current)</span>              
                            </a>
                        </li>

                        <!-- <li class="nav-item active">
                            <a class="nav-link" href="/">
                                Contact              
                                <span class="sr-only">(current)</span>              
                            </a>
                        </li> -->

                    </ul>
                </div>
            </div>
        </nav>

    </header>


    <!-- Content -->

    <div class="container mt-5">
        <div class="post">

            <header class="post-header">
                <h1 class="post-title-research-page">
                    <span class="font-weight-bold"><span style="color: red;">Research</span></span>
                </h1>
                <p class="desc"></p>
            </header>

            <article>

                <div class="clearfix">
                    <p>
                        Our research can be divided into several topic areas.
                    </p>
                    <p>
                        1. Theory of machine learning through the lens of symmetry including generalization and approximation error for equivariant neural networks, study of approximate and extrinsic symmetry in deep learning, symmetries of neural network parameters spaces and
                        their effects on optimization, structure of equivariant neural networks.
                    </p>
                    <p>
                        2. Design of equivariant neural networks for scientific and engineering applications including fluid dynamics, radar signal processing, astrophysical simulation, radar signal processing, and materials and thin films.
                    </p>
                    <p>
                        3. Equivariant methods for deep reinforcement learning with an emphasis on robotic learning and perception. Our goals are sample efficient algorithms for real world robot learning.
                    </p>
                    <p>
                        4. Design models that can utilize approximate and unknown symmetry. These include symmetry discovery methods, relaxed equivariant methods, applications of equivariant models in cases of extrinsic symmetry, and methods that can learn group actions in
                        cases of latent symmetry.
                    </p>

                </div>

            </article>

            <article>

                <header class="post-header">
                    <h1 class="post-title-research-page">
                        <span class="font-weight-bold">Selected Publications</span>
                    </h1>
                    <p class="desc"></p>
                </header>

                <div class="publications">


<!---------------------ROGERS HOLLOW EDIT ------------------->
<!------------------------- 2 0 2 5 ------------------------->

 <!-- Push-grasp policy learning using equivariant models and grasps core optimization. -->
<h2 class="year">2025</h2>
    <ol class="bibliography">
        <li>
            <div class="row">
                 <div class="col-sm-3 abbr">
                 <abbr class="badge">RAL 2025</abbr>
                 <img src="https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs10514-023-10112-w/MediaObjects/10514_2023_10112_Fig6_HTML.png" alt="Project Image" style="object-fit: contain;">
                </div>

                 <div id="iClarify" class="col-sm-8">
                    <div class="title">Push-grasp policy learning using equivariant models and grasps core optimization.</div>
                    <div class="author">
                    <a href="https://bocehu.github.io/" target="_blank" rel="noopener noreferrer">Boce Hu*</a>,
                    <a href="https://scholar.google.com/citations?user=pkkjUEUAAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Heng Tian*</a>,
                    <a href="https://pointw.github.io/" target="_blank" rel="noopener noreferrer">Dian Wang</a>
                    <a href="https://haojhuang.github.io/" target="_blank" rel="noopener noreferrer">Haojie Huang</a>
                    <a href="https://zxp-s-works.github.io/" target="_blank" rel="noopener noreferrer">Xupeng Zhu</a>
                    <a href="" target="_blank" rel="noopener noreferrer">Robin Walters</a>
                    <a href="https://helpinghandslab.netlify.app/people/" target="_blank" rel="noopener noreferrer">Robert Platt</a>
                    </div>

                    <div class="periodical">
                         <em>
                        IEEE Robotics and Automation Letters (RAL), 2025.
                         </em>
                    </div>


                    <div class="links">
                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                        <a href="https://arxiv.org/pdf/2504.03053" class="btn btn-sm z-depth-0" role="button">PDF</a>
                        <a href="https://arxiv.org/abs/2504.03053" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                    </div>

<!-- Hidden abstract block -->
    <div class="abstract hidden">
        <p>Goal-conditioned robotic grasping in cluttered environments remains a challenging problem due to occlusions caused by surrounding objects, which prevent direct access to the target object. A promising solution to mitigate this issue is combining pushing and grasping policies, enabling active rearrangement of the scene to facilitate target retrieval. However, existing methods often overlook the rich geometric structures inherent in such tasks, thus limiting their effectiveness in complex, heavily cluttered scenarios. To address this, we propose the Equivariant Push-Grasp Network, a novel framework for joint pushing and grasping policy learning. Our contributions are twofold: (1) leveraging SE(2)-equivariance to improve both pushing and grasping performance and (2) a grasp score optimization-based training strategy that simplifies the joint learning process. Experimental results show that our method improves grasp success rates by 49% in simulation and by 35% in real-world scenarios compared to strong baselines, representing a significant advancement in push-grasp policy learning.</p>
</div>
<!-- Hidden bibtex block -->
</div>
</div>
</li>
</ol>


 <!-- Learning efficient and robust language-conditioned manipulation using textual-visual relevancy and equivariant language mapping. -->
<h2 class="year">2025</h2>
    <ol class="bibliography">
        <li>
            <div class="row">
                 <div class="col-sm-3 abbr">
                 <abbr class="badge">RAL 2025</abbr>
                 <img src="https://www.dianwang.io/images/haibo_hep.png" alt="Project Image" style="object-fit: contain;">
                </div>

                 <div id="iClarify" class="col-sm-8">
                    <div class="title">Learning efficient and robust language-conditioned manipulation using textual-visual relevancy and equivariant language mapping.</div>
                    <div class="author">
                    <a href="https://saulbatman.github.io/" target="_blank" rel="noopener noreferrer">Mingxi Jia</a>,
                    <a href="https://haojhuang.github.io/" target="_blank" rel="noopener noreferrer">Haojie Huang</a>,
                    <a href="https://dl.acm.org/profile/99661213150" target="_blank" rel="noopener noreferrer">Zhewen Zhang</a>,
                    <a href="https://scholar.google.com/citations?user=Vlx-PYwAAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Chenghao Wang</a>,
                    <a href="https://lfzhao.com/" target="_blank" rel="noopener noreferrer">Linfeng Zhao</a>,
                    <a href="https://pointw.github.io/" target="_blank" rel="noopener noreferrer">Dian Wang</a>,
                    <a href="https://jasonxyliu.github.io/" target="_blank" rel="noopener noreferrer">Jason Xinyu Liu</a>,
                    <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>,
                    <a href="https://helpinghandslab.netlify.app/people/" target="_blank" rel="noopener noreferrer">Robert Platt*</a>,
                    <a href="https://dl.acm.org/profile/81100089105" target="_blank" rel="noopener noreferrer">Stefanie Tellex*</a>
                    </div>

                    <div class="periodical">
                         <em>
                        IEEE Robotics and Automation Letters (RAL), 2025.
                         </em>
                    </div>


                    <div class="links">
                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                        <a href="https://arxiv.org/html/2406.15677v2" class="btn btn-sm z-depth-0" role="button">PDF</a>
                        <a href="https://arxiv.org/html/2406.15677v2" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                    </div>

<!-- Hidden abstract block -->
    <div class="abstract hidden">
        <p>Controlling robots through natural language is pivotal for enhancing human-robot collaboration and synthesizing complex robot behaviors. Recent works that are trained on large robot datasets show impressive generalization abilities. However, such pretrained methods are (1) often fragile to unseen scenarios, and (2) expensive to adapt to new tasks. This paper introduces Grounded Equivariant Manipulation (GEM), a robust yet efficient approach that leverages pre-trained vision-language models with equivariant language mapping for language-conditioned manipulation tasks. Our experiments demonstrate GEM’s high sample efficiency and generalization ability across diverse tasks in both simulation and the real world. GEM achieves similar or higher performance with orders of magnitude fewer robot data compared with major data-efficient baselines such as CLIPort and VIMA. Finally, our approach demonstrates greater robustness compared to large VLA model, e.g, OpenVLA, at correctly interpreting natural language commands on unseen objects and poses. Code, data, and training details are available <a href="https://saulbatman.github.io/gem_page/">HERE.</a>

</p>
</div>
<!-- Hidden bibtex block -->
</div>
</div>
</li>
</ol>

<!-- Reducing the sensitivity of neural physics simulator stomeshtopology via pretraining. -->
<h2 class="year">2025</h2>
    <ol class="bibliography">
        <li>
            <div class="row">
                 <div class="col-sm-3 abbr">
                 <abbr class="badge">ICASSP 2025</abbr>
                 <img src="https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs00366-023-01904-w/MediaObjects/366_2023_1904_Fig1_HTML.png" alt="Project Image" style="object-fit: contain;">
                </div>

                 <div id="iClarify" class="col-sm-8">
                    <div class="title">Reducing the Sensitivity of Neural Physics Simulators to Mesh Topology via Pretraining</div>
                    <div class="author">
                    <a href="https://www.linkedin.com/in/nathanvaska/" target="_blank" rel="noopener noreferrer">Nathan Vaska</a>,
                    <a href="https://dblp.org/pid/241/5316.html" target="_blank" rel="noopener noreferrer">Justin Goodwin</a>,
                    <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>,
                    <a href="https://helpinghandslab.netlify.app/people/" target="_blank" rel="noopener noreferrer">Rajmonda Caceres</a>
                    </div>

                    <div class="periodical">
                         <em>
                        International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2025.
                         </em>
                    </div>


                    <div class="links">
                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                        <a href="https://arxiv.org/pdf/2501.09597" class="btn btn-sm z-depth-0" role="button">PDF</a>
                        <a href="https://arxiv.org/abs/2501.09597" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                    </div>

<!-- Hidden abstract block -->
    <div class="abstract hidden">
        <p>Meshes are used to represent complex objects in high fidelity physics simulators across a variety of domains, such as radar sensing and aerodynamics. There is growing interest in using neural networks to accelerate physics simulations, and also a growing body of work on applying neural networks directly to irregular mesh data. Since multiple mesh topologies can represent the same object, mesh augmentation is typically required to handle topological variation when training neural networks. Due to the sensitivity of physics simulators to small changes in mesh shape, it is challenging to use these augmentations when training neural network-based physics simulators. In this work, we show that variations in mesh topology can significantly reduce the performance of neural network simulators. We evaluate whether pretraining can be used to address this issue, and find that employing an established autoencoder pretraining technique with graph embedding models reduces the sensitivity of neural network simulators to variations in mesh topology. Finally, we highlight future research directions that may further reduce neural simulator sensitivity to mesh topology.</p>
</div>
<!-- Hidden bibtex block -->
</div>
</div>
</li>
</ol>


 <!-- Approximate equivariance in reinforcement learning. -->
<h2 class="year">2025</h2>
    <ol class="bibliography">
        <li>
            <div class="row">
                 <div class="col-sm-3 abbr">
                 <abbr class="badge">AISTATS 2025</abbr>
                 <img src="https://www.researchgate.net/publication/385630242/figure/fig4/AS:11431281289098540@1731035551433/llustration-of-an-approximately-D-2-equivariant-encoder-and-policy-using-relaxed_Q320.jpg" alt="Project Image" style="object-fit: contain;">
                </div>

                 <div id="iClarify" class="col-sm-8">
                    <div class="title">Approximate equivariance in reinforcement learning.</div>
                    <div class="author">
                    <a href="https://jypark0.github.io/" target="_blank" rel="noopener noreferrer">Jung Yeon Park*</a>,
                    <a href="https://ieeexplore.ieee.org/author/37085845673" target="_blank" rel="noopener noreferrer">Sujay Bhatt</a>,
                    <a href="https://dblp.org/pid/209/3016" target="_blank" rel="noopener noreferrer">Sihan Zeng</a>,
                    <a href="https://www.khoury.northeastern.edu/home/lsw/" target="_blank" rel="noopener noreferrer">Lawson L.S. Wong*</a>,
                    <a href="https://koppel.netlify.app/" target="_blank" rel="noopener noreferrer">Alec Koppel</a>,
                    <a href="https://scholar.google.com/citations?user=B6t9KM8AAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Sumitra Ganesh</a>,
                    <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters*</a>
                    </div>

                    <div class="periodical">
                         <em>
                        Artificial Intelligence and Statistics (AISTATS), 2025.
                         </em>
                    </div>


                    <div class="links">
                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                        <a href="https://arxiv.org/pdf/2411.04225" class="btn btn-sm z-depth-0" role="button">PDF</a>
                        <a href="https://arxiv.org/abs/2411.04225" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                    </div>

<!-- Hidden abstract block -->
    <div class="abstract hidden">
        <p>Equivariant neural networks have shown great success in reinforcement learning, improving sample efficiency and generalization when there is symmetry in the task. However, in many problems, only approximate symmetry is present, which makes imposing exact symmetry inappropriate. Recently, approximately equivariant networks have been proposed for supervised classification and modeling physical systems. In this work, we develop approximately equivariant algorithms in reinforcement learning (RL). We define approximately equivariant MDPs and theoretically characterize the effect of approximate equivariance on the optimal Q function. We propose novel RL architectures using relaxed group and steerable convolutions and experiment on several continuous control domains and stock trading with real financial data. Our results demonstrate that the approximately equivariant network performs on par with exactly equivariant networks when exact symmetries are present, and outperforms them when the domains exhibit approximate symmetry. As an added byproduct of these techniques, we observe increased robustness to noise at test time.</p>
</div>
<!-- Hidden bibtex block -->
</div>
</div>
</li>
</ol>


 <!-- Hierarchical equivariant policy via frame transfer. -->
                    <h2 class="year">2025</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">ICML 2025</abbr>
                                    <img src="https://moonlight-paper-snapshot.s3.ap-northeast-2.amazonaws.com/arxiv/hierarchical-equivariant-policy-via-frame-transfer-0.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Hierarchical equivariant policy via frame transfer.</div>
                                    <div class="author">
                                        <a href="https://www.linkedin.com/in/haibo-zhao-b68742250/" target="_blank" rel="noopener noreferrer">Haibo Zhao*</a>,
                                        <a href="https://pointw.github.io/" target="_blank" rel="noopener noreferrer">Dian Wang*</a>,
                                        <a href="https://www.linkedin.com/in/yizhe-zhu-15458ba0/" target="_blank" rel="noopener noreferrer">Yizhe Zhu</a>,
                                        <a href="https://zxp-s-works.github.io/" target="_blank" rel="noopener noreferrer">Xupeng Zhu</a>, 
                                         <a href="https://www.linkedin.com/in/ohowell123/" target="_blank" rel="noopener noreferrer">Owen Lewis Howell</a>,
                                        <a href="https://lfzhao.com/" target="_blank" rel="noopener noreferrer">Linfeng Zhao</a>,
                                        <a href="https://h-freax.github.io/" target="_blank" rel="noopener noreferrer">Yaoyao Qian</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>,
                                        <a href="https://helpinghandslab.netlify.app/people/" target="_blank" rel="noopener noreferrer">Robert Platt</a>
                                        
                                    </div>

                                    <div class="periodical">
                                        <em>In Forty-second International Conference on Machine Learning (ICML), 2025.</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2502.05728" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://arxiv.org/abs/2502.05728" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Recent advances in hierarchical policy learning highlight the advantages of decomposing systems into high-level and low-level agents, enabling efficient long-horizon reasoning and precise fine-grained control. However, the interface between these hierarchy levels remains underexplored, and existing hierarchical methods often ignore domain symmetry, resulting in the need for extensive demonstrations to achieve robust performance. To address these issues, we propose Hierarchical Equivariant Policy (HEP), a novel hierarchical policy framework. We propose a frame transfer interface for hierarchical policy learning, which uses the high-level agent's output as a coordinate frame for the low-level agent, providing a strong inductive bias while retaining flexibility. Additionally, we integrate domain symmetries into both levels and theoretically demonstrate the system's overall equivariance. HEP achieves state-of-the-art performance in complex robotic manipulation tasks, demonstrating significant improvements in both simulation and real-world settings.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>



 <!-- Understanding mode connectivity via parameter space symmetry -->
                    <h2 class="year">2025</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">ICML 2025</abbr>
                                    <img src="https://moonlight-paper-snapshot.s3.ap-northeast-2.amazonaws.com/arxiv/understanding-mode-connectivity-via-parameter-space-symmetry-3.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Understanding Mode Connectivity via Parameter Space Symmetry</div>
                                    <div class="author">
                                        <a href="https://b-zhao.github.io/" target="_blank" rel="noopener noreferrer">Bo Zhao</a>,
                                        <a href="https://nimadehmamy.github.io/" target="_blank" rel="noopener noreferrer">Nima Dehmamy</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>,
                                        <a href="https://roseyu.com/" target="_blank" rel="noopener noreferrer">Rose Yu</a>
                                        
                                    </div>

                                    <div class="periodical">
                                        <em>In Forty-second International Conference on Machine Learning (ICML), 2025.</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2505.23681" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://arxiv.org/abs/2505.23681" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Neural network minima are often connected by curves along which train and test loss remain nearly constant, a phenomenon known as mode connectivity. While this property has enabled applications such as model merging and fine-tuning, its theoretical explanation remains unclear. We propose a new approach to exploring the connectedness of minima using parameter space symmetry. By linking the topology of symmetry groups to that of the minima, we derive the number of connected components of the minima of linear networks and show that skip connections reduce this number. We then examine when mode connectivity and linear mode connectivity hold or fail, using parameter symmetries which account for a significant part of the minimum. Finally, we provide explicit expressions for connecting curves in the minima induced by symmetry. Using the curvature of these curves, we derive conditions under which linear mode connectivity approximately holds. Our findings highlight the role of continuous symmetries in understanding the neural network loss landscape.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>



 <!-- Se (3)-equivariant diffusion policy in spherical fourier space. In Forty-second International Conference on Machine Learning (ICML), 2025. -->
                    <h2 class="year">2025</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">ICML 2025</abbr>
                                    <img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSwkNAbj4GrNBfYgIHw4d80YCe5rPWU6RRtHw&s" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Se (3)-equivariant diffusion policy in spherical fourier space.</div>
                                    <div class="author">
                                        <a href="https://zxp-s-works.github.io/" target="_blank" rel="noopener noreferrer">Xupeng Zhu</a>,
                                        <a href="https://scholar.google.com/citations?user=1Bu6nbcAAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Fan Wang</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>,
                                        <a href="https://dblp.org/pid/20/7747.html" target="_blank" rel="noopener noreferrer">Jane Shi</a>
                                        
                                    </div>

                                    <div class="periodical">
                                        <em>In Forty-second International Conference on Machine Learning (ICML), 2025.</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2507.01723" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://arxiv.org/abs/2507.01723" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>
                                            Diffusion Policies are effective at learning closed-loop manipulation policies from human demonstrations but generalize poorly to novel arrangements of objects in 3D space, hurting real-world performance. To address this issue, we propose Spherical Diffusion Policy (SDP), an SE(3) equivariant diffusion policy that adapts trajectories according to 3D transformations of the scene. Such equivariance is achieved by embedding the states, actions, and the denoising process in spherical Fourier space. Additionally, we employ novel spherical FiLM layers to condition the action denoising process equivariantly on the scene embeddings. Lastly, we propose a spherical denoising temporal U-net that achieves spatiotemporal equivariance with computational efficiency. In the end, SDP is end-to-end SE(3) equivariant, allowing robust generalization across transformed 3D scenes. SDP demonstrates a large performance improvement over strong baselines in 20 simulation tasks and 5 physical robot tasks including single-arm and bi-manual embodiments. Code is available at this https URL.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>


                    <!-- Equivariant action sampling for reinforcement learning and planning. -->
                    <h2 class="year">2025</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">WAFR 2025</abbr>
                                    <img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ5_HSMGlB2Zzrl5qsSEj1kLA1p-N2vLA51Zw&s" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Equivariant action sampling for reinforcement learning and planning.</div>
                                    <div class="author">
                                        <a href="https://lfzhao.com/" target="_blank" rel="noopener noreferrer">Linfeng Zhao</a>,
                                        <a href="" target="_blank" rel="noopener noreferrer">Owen Howell</a>,
                                        <a href="https://zxp-s-works.github.io/" target="_blank" rel="noopener noreferrer">Xupeng Zhu</a>,
                                        <a href="https://jypark0.github.io/" target="_blank" rel="noopener noreferrer">Jung Yeon Park</a>,
                                        <a href="https://dl.acm.org/profile/99661213150" target="_blank" rel="noopener noreferrer">Zhewen Zhang</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>,
                                        <a href="https://www.khoury.northeastern.edu/home/lsw/" target="_blank" rel="noopener noreferrer">Lawson L.S. Wong</a>
                                        
                                    </div>

                                    <div class="periodical">
                                        <em>Workshop on the Algorithmic Foundations of Robotics (WAFR), 2025. </em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2412.12237" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://arxiv.org/abs/2412.12237" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>
                                            Reinforcement learning (RL) algorithms for continuous control tasks require accurate sampling-based action selection. Many tasks, such as robotic manipulation, contain inherent problem symmetries. However, correctly incorporating symmetry into sampling-based approaches remains a challenge. This work addresses the challenge of preserving symmetry in sampling-based planning and control, a key component for enhancing decision-making efficiency in RL. We introduce an action sampling approach that enforces the desired symmetry. We apply our proposed method to a coordinate regression problem and show that the symmetry aware sampling method drastically outperforms the naive sampling approach. We furthermore develop a general framework for sampling-based model-based planning with Model Predictive Path Integral (MPPI). We compare our MPPI approach with standard sampling methods on several continuous control tasks. Empirical demonstrations across multiple continuous control environments validate the effectiveness of our approach, showcasing the importance of symmetry preservation in sampling-based action selection.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                   <!-- Data-Free Transformer Quantization Using Parameter-Space Symmetry. -->
                    <h2 class="year">2025</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">HDLDW 2025</abbr>
                                    <img src="../publications/images/DataFreeTransformer.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Data-Free Transformer Quantization Using Parameter-Space Symmetry.</div>
                                    <div class="author">
                                        <a href="https://openreview.net/profile?id=~Lucas_Laird1" target="_blank" rel="noopener noreferrer">Lucas Laird</a>,
                                        <a href="https://www.linkedin.com/in/haibo-zhao-b68742250/" target="_blank" rel="noopener noreferrer">Bo Zhao</a>,
                                        <a href="https://roseyu.com/" target="_blank" rel="noopener noreferrer">Rose Yu</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>
                                        
                                    </div>

                                    <div class="periodical">
                                        <em>High-Dimensional Learning Dynamics Workshop, 2025.</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://openreview.net/pdf?id=NBbuA7Ud0I" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://icml.cc/virtual/2025/47681" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>
                                           Transformer models have seen widespread use in many learning tasks but incur large memory and compute costs, limiting their deployability. Post-Training Quantization (PTQ) is a promising solution but can lead to significant performance degradation. Many PTQ methods estimate weight and activation distributions with calibration data to account for outliers and maintain quantized performance. We propose a data-free approach to improve quantization by exploiting parameter space symmetries. We address outliers and high variability in weights by finding a transformation of the model weights that minimizes quantization error variance. Our approach is light-weight, data-free, and can be integrated as a pre-processing step within other PTQ methods. We evaluate our approach by testing quantized large language models on several benchmark tasks. 
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>



<!------------------------- 2 0 2 4 ------------------------->


                    <!-- Symmetry-informed governing equation discovery. Neural Information Processing Systems (NeurIPS), 2024. -->
                    <h2 class="year">2024</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">NeurIPS & ICLR 2024</abbr>
                                    <img src="https://research.nvidia.com/labs/par/publication/the_empirical_impact_of_neural_parameter_symmetries/featured_hu15b073a6ffb94876a898b94bc36a2a77_108542_720x0_resize_lanczos_3.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">The Empirical Impact of Neural Parameter Symmetries, or Lack Thereof</div>
                                    <div class="author">
                                        <a href="https://cptq.github.io/about/" target="_blank" rel="noopener noreferrer">Derek Lim*</a>,
                                        <a href="https://sites.google.com/berkeley.edu/moeputterman/home?authuser=0" target="_blank" rel="noopener noreferrer">Moe Putterman*</a>,
                                        <a href="https://haggaim.github.io/" target="_blank" rel="noopener noreferrer">Haggai Maron</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>
                                         <a href="https://scholar.google.com/citations?user=gTWUZlsAAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Stefanie Jegelka</a>
                                        
                                    </div>

                                    <div class="periodical">
                                        <em>Neural Information Processing Systems (NeurIPS) and Best Paper at Workshop on High-Dimensional Learning Dynamics (HiLD) at ICLR, 2024.</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/31d1946b6bccf54bdd4a811bedd9626b-Paper-Conference.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/31d1946b6bccf54bdd4a811bedd9626b-Paper-Conference.pdf" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>
                                            Many algorithms and observed phenomena in deep learning appear to be affected by parameter symmetries — transformations of neural network parameters that do not change the underlying neural network function. These include linear mode connectivity, model merging, Bayesian neural network inference, metanetworks, and several other characteristics of optimization or loss-landscapes. However, theoretical analysis of the relationship between parameter space symmetries and these phenomena is difficult. In this work, we empirically investigate the impact of neural parameter symmetries by introducing new neural network architectures that have reduced parameter space symmetries. We develop two methods, with some provable guarantees, of modifying standard neural networks to reduce parameter space symmetries. With these new methods, we conduct a comprehensive experimental study consisting of multiple tasks aimed at assessing the effect of removing parameter symmetries. Our experiments reveal several interesting observations on the empirical impact of parameter symmetries; for instance, we observe linear mode connectivity between our networks without alignment of weight spaces, and we find that our networks allow for faster and more effective Bayesian neural network training. Our code is available at https://github.com/cptq/asymmetric-networks.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>


                    <!-- Matrixnet: Learning over symmetry groups using learned group representations. -->
                    <h2 class="year">2024</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">NeurIPS 2024</abbr>
                                    <img src="https://moonlight-paper-snapshot.s3.ap-northeast-2.amazonaws.com/arxiv/matrixnet-learning-over-symmetry-groups-using-learned-group-representations-4.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Matrixnet: Learning over symmetry groups using learned group representations.</div>
                                    <div class="author">
                                        <a href="https://openreview.net/profile?id=~Lucas_Laird1" target="_blank" rel="noopener noreferrer">Lucas Laird</a>,
                                        <a href="https://nullspac.es/" target="_blank" rel="noopener noreferrer">Circe Hsu</a>,
                                        <a href="https://asilata.github.io/" target="_blank" rel="noopener noreferrer">Asilata Bapat</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>
                                        
                                    </div>

                                    <div class="periodical">
                                        <em> Neural Information Processing Systems(NeurIPS), 2024.</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/39137b5a573126103c8812dcdb9d0187-Paper-Conference.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/39137b5a573126103c8812dcdb9d0187-Paper-Conference.pdf" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                        <!-- <a href="https://zenodo.org/records/10359729" class="btn btn-sm z-depth-0" role="button">Dataset</a> -->
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>
                                            Group theory has been used in machine learning to provide a theoretically grounded approach for incorporating known symmetry transformations in tasks from robotics to protein modeling. In these applications, equivariant neural networks use known symmetry groups with predefined representations to learn over geometric input data. We propose MatrixNet, a neural network architecture that learns matrix representations of group element inputs instead of using predefined representations. MatrixNet achieves higher sample efficiency and generalization over several standard baselines in prediction tasks over the several finite groups and the Artin braid group. We also show that MatrixNet respects group relations allowing generalization to group elements of greater word length than in the training set. Our code is available at https://github.com/lucas-laird/MatrixNet.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>



                    <!-- Symmetry-informed governing equation discovery. Neural Information Processing Systems (NeurIPS), 2024. -->
                    <h2 class="year">2024</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">NeurIPS 2024</abbr>
                                    <img src="https://moonlight-paper-snapshot.s3.ap-northeast-2.amazonaws.com/arxiv/symmetry-informed-governing-equation-discovery-4.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Symmetry-Informed Governing Equation Discovery</div>
                                    <div class="author">
                                        <a href="https://scholar.google.com/citations?user=pO9PnCUAAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Jianke Yang</a>,
                                        <a href="https://scholar.google.com/citations?user=o2MaIRUAAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Wang Rao</a>,
                                        <a href="https://nimadehmamy.github.io/" target="_blank" rel="noopener noreferrer">Nima Dehmamy</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>,
                                        <a href="https://roseyu.com/" target="_blank" rel="noopener noreferrer">Rose Yu</a>,
                                        
                                    </div>

                                    <div class="periodical">
                                        <em> Neural Information Processing Systems (NeurIPS), 2024.</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://www.proceedings.com/content/079/079017-2085open.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://proceedings.neurips.cc/paper_files/paper/2024/hash/77fa0e7d45c6687f1958de0b31e9fc05-Abstract-Conference.html" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                        <!-- <a href="https://zenodo.org/records/10359729" class="btn btn-sm z-depth-0" role="button">Dataset</a> -->
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>
                                            Despite the advancements in learning governing differential equations from observations of dynamical systems, data-driven methods are often unaware of fundamental physical laws, such as frame invariance. As a result, these algorithms may search an unnecessarily large space and discover less accurate or overly complex equations. In this paper, we propose to leverage symmetry in automated equation discovery to compress the equation search space and improve the accuracy and simplicity of the learned equations. Specifically, we derive equivariance constraints from the time-independent symmetries of ODEs. Depending on the types of symmetries, we develop a pipeline for incorporating symmetry constraints into various equation discovery algorithms, including sparse regression and genetic programming. In experiments across diverse dynamical systems, our approach demonstrates better robustness against noise and recovers governing equations with significantly higher probability than baselines without symmetry.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>




                    <!-- Equivariant Diffusion Policy -->
                    <h2 class="year">2024</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">CoRL 2024</abbr>
                                    <img src="../publications/images/dian_corl24.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Equivariant Diffusion Policy</div>
                                    <div class="author">
                                        <a href="https://pointw.github.io/" target="_blank" rel="noopener noreferrer">Dian Wang*</a>,
                                        <a href="https://www.linkedin.com/in/stephen-hart-3711666/" target="_blank" rel="noopener noreferrer">Stephen Hart</a>,
                                        <a href="https://www.linkedin.com/in/surovik/" target="_blank" rel="noopener noreferrer">David Surovik</a>,
                                        <a href="https://kelestemur.com/" target="_blank" rel="noopener noreferrer">Tarik Kelestemur</a>,
                                        <a href="https://haojhuang.github.io/" target="_blank" rel="noopener noreferrer">Haojie Huang</a>,
                                        <a href="https://www.linkedin.com/in/haibo-zhao-b68742250/" target="_blank" rel="noopener noreferrer">Haibo Zhao</a>,
                                        <a href="https://www.linkedin.com/in/mark-yeatman-58a49763/" target="_blank" rel="noopener noreferrer">Mark Yeatman</a>,
                                        <a href="https://www.robo.guru/" target="_blank" rel="noopener noreferrer">Jiuguang Wang</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>,
                                        <a href="https://helpinghandslab.netlify.app/people/" target="_blank" rel="noopener noreferrer">Robert Platt</a>
                                    </div>

                                    <div class="periodical">
                                        <em>Conference on Robot Learning 2024</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2407.01812" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://equidiff.github.io/" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>
                                            Recent work has shown diffusion models are an effective approach to learning the multimodal distributions arising from demonstration data in behavior cloning. However, a drawback of this approach is the need to learn a denoising function, which is significantly more complex than learning an explicit policy. In this work, we propose Equivariant Diffusion Policy, a novel diffusion policy learning method that leverages domain symmetries to obtain better sample efficiency and generalization in the denoising function. We theoretically analyze the SO(2) symmetry of full 6-DoF control and characterize when a diffusion model is SO(2)-equivariant. We furthermore evaluate the method empirically on a set of 12 simulation tasks in MimicGen, and show that it obtains a success rate that is, on average, 21.9% higher than the baseline Diffusion Policy. We also evaluate the method on a real-world system to show that effective policies can be learned with relatively few training samples, whereas the baseline Diffusion Policy cannot.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>



                     <!-- Orbitgrasp: se(3)-equivariant grasp learning. -->
                    <h2 class="year">2024</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">CoRL 2024</abbr>
                                    <img src="https://orbitgrasp.github.io/static/images/orbit.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">OrbitGrasp: SE(3)-Equivariant Grasp Learning</div>
                                    <div class="author">
                                        <a href="https://bocehu.github.io/" target="_blank" rel="noopener noreferrer">Boce Hu</a>,
                                        <a href="https://zxp-s-works.github.io/" target="_blank" rel="noopener noreferrer">Xupeng Zhu</a>,
                                        <a href="https://pointw.github.io/" target="_blank" rel="noopener noreferrer">Dian Wang*</a>,
                                        <a href="" target="_blank" rel="noopener noreferrer">Zihao Dong</a>,
                                        <a href="https://haojhuang.github.io/" target="_blank" rel="noopener noreferrer">Haojie Huang*</a>,
                                        <a href="https://scholar.google.com/citations?user=Vlx-PYwAAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Chenghao Wang*</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>,
                                        <a href="https://helpinghandslab.netlify.app/people/" target="_blank" rel="noopener noreferrer">Robert Platt</a>
                                    </div>

                                    <div class="periodical">
                                        <em>Conference on Robot Learning (CoRL), 2024.</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2407.03531" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://arxiv.org/abs/2407.03531" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>
                                            While grasp detection is an important part of any robotic manipulation pipeline, reliable and accurate grasp detection in SE(3) remains a research challenge. Many robotics applications in unstructured environments such as the home or warehouse would benefit a lot from better grasp performance. This paper proposes a novel framework for detecting SE(3) grasp poses based on point cloud input. Our main contribution is to propose an SE(3)-equivariant model that maps each point in the cloud to a continuous grasp quality function over the 2-sphere S2 using spherical harmonic basis functions. Compared with reasoning about a finite set of samples, this formulation improves the accuracy and efficiency of our model when a large number of samples would otherwise be needed. In order to accomplish this, we propose a novel variation on EquiFormerV2 that leverages a UNet-style encoder-decoder architecture to enlarge the number of points the model can handle. Our resulting method, which we name OrbitGrasp, significantly outperforms baselines in both simulation and physical experiments.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>



                    <!-- haojie Imagination Policy Corl 2024 -->
                    <h2 class="year">2024</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">CoRL 2024</abbr>
                                    <img src="../publications/images/corl_imagine.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">IMAGINATION POLICY: Using Generative Point Cloud Models for Learning Manipulation Policies</div>
                                    <div class="author">
                                        <a href="https://haojhuang.github.io/" target="_blank" rel="noopener noreferrer">Haojie Huang</a>,
                                        <a href="https://sites.google.com/view/karlschmeckpeper" target="_blank" rel="noopener noreferrer">Karl Schmeckpeper</a>,
                                        <a href="https://pointw.github.io/" target="_blank" rel="noopener noreferrer">Dian Wang</a>,
                                        <a href="https://ondrejbiza.com/#" target="_blank" rel="noopener noreferrer">Ondrej Biza</a>,
                                        <a href="https://h-freax.github.io/" target="_blank" rel="noopener noreferrer">Yaoyao Qian</a>,
                                        <a href="https://seanliu7081.github.io/" target="_blank" rel="noopener noreferrer">Haotian Liu</a>,
                                        <a href="https://saulbatman.github.io/" target="_blank" rel="noopener noreferrer">Mingxi Jia</a>,
                                        <a href="https://helpinghandslab.netlify.app/people/" target="_blank" rel="noopener noreferrer">Robert Platt</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>
                                    </div>

                                    <div class="periodical">
                                        <em>Conference on Robot Learning 2024</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://openreview.net/forum?id=56IzghzjfZ" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://haojhuang.github.io/imagine_page/" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                        <!-- <a href="https://zenodo.org/records/10359729" class="btn btn-sm z-depth-0" role="button">Dataset</a> -->
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>
                                            Humans can imagine goal states during planning and perform actions to match those goals. In this work, we propose IMAGINATION POLICY, a novel multi-task key-frame policy network for solving high-precision pick and place tasks. Instead of learning actions directly, IMAGINATION POLICY generates point clouds to imagine desired states which are then translated to actions using rigid action estimation. This transforms action inference into a local generative task. We leverage pick and place symmetries underlying the tasks in the generation process and achieve extremely high sample efficiency and generalizability to unseen configurations. Finally, we demonstrate state-of-the-art performance across various tasks on the RLbench benchmark compared with several strong baselines and validate our approach on a real robot.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <!-- haojie FourTran icrl 2024 -->
                    <h2 class="year">2024</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">ICLR 2024</abbr>
                                    <img src="../publications/images/iclr_foutran.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Fourier Transporter: Bi-Equivariant Robotic Manipulation in 3D</div>
                                    <div class="author">
                                        <a href="https://haojhuang.github.io/" target="_blank" rel="noopener noreferrer">Haojie Huang</a>,
                                        <a href="https://owenhowell20.github.io/" target="_blank" rel="noopener noreferrer">Owen Howell*</a>,
                                        <a href="https://pointw.github.io/" target="_blank" rel="noopener noreferrer">Dian Wang*</a>,
                                        <a href="https://zxp-s-works.github.io/" target="_blank" rel="noopener noreferrer">Xupeng Zhu*</a>,
                                        <a href="https://helpinghandslab.netlify.app/people/" target="_blank" rel="noopener noreferrer">Robert Platt**</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters**</a>
                                    </div>

                                    <div class="periodical">
                                        <em>The International Conference on Learning Representations 2024</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://openreview.net/forum?id=UulwvAU1W0" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://haojhuang.github.io/fourtran_page/" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                        <!-- <a href="https://zenodo.org/records/10359729" class="btn btn-sm z-depth-0" role="button">Dataset</a> -->
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>
                                            Many complex robotic manipulation tasks can be decomposed as a sequence of pick and place actions. Training a robotic agent to learn this sequence over many different starting conditions typically requires many iterations or demonstrations, especially in 3D environments. In this work, we propose Fourier Transporter ( ), which leverages the two-fold symmetry in the pick-place problem to achieve much higher sample efficiency. is an open-loop behavior cloning method trained using expert demonstrations to predict pick-place actions on new configurations. is constrained by the symmetries of the pick and place actions independently. Our method utilizes a fiber space Fourier transformation that allows for memory-efficient computation. Tests on the RLbench benchmark achieve state-of-the-art results across various tasks.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>


                    <!-- Improving convergence and generalization using parameter symmetries -->
                    <h2 class="year">2024</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">ICLR 2024</abbr>
                                    <img src="../publications/images/ImprovingConvergence.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Improving convergence and generalization using parameter symmetries</div>
                                    <div class="author">
                                        <a href="https://b-zhao.github.io/" target="_blank" rel="noopener noreferrer">Bo Zhao*</a>,
                                        <a href="https://gowerrobert.github.io/" target="_blank" rel="noopener noreferrer">Robert M Gower*</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters*</a>,
                                        <a href="https://roseyu.com/" target="_blank" rel="noopener noreferrer">Rose Yu*</a>
                                        
                                    </div>

                                    <div class="periodical">
                                        <em>International Conference on Learning Representations (ICLR), Oral, 2024.</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2401.12046" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://arxiv.org/abs/2401.12046" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                        <!-- <a href="https://zenodo.org/records/10359729" class="btn btn-sm z-depth-0" role="button">Dataset</a> -->
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>
                                            Many complex robotic manipulation tasks can be decomposed as a sequence of pick and place actions. Training a robotic agent to learn this sequence over many different starting conditions typically requires many iterations or demonstrations, especially in 3D environments. In this work, we propose Fourier Transporter (FourTran) which leverages the two-fold SE(d)xSE(d) symmetry in the pick-place problem to achieve much higher sample efficiency. FourTran is an open-loop behavior cloning method trained using expert demonstrations to predict pick-place actions on new environments. FourTran is constrained to incorporate symmetries of the pick and place actions independently. Our method utilizes a fiber space Fourier transformation that allows for memory-efficient construction. We test our proposed network on the RLbench benchmark and achieve state-of-the-art results across various tasks.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                     <!-- Fast and Expressive Gesture Recognition using a Combination-Homomorphic Electromyogram Encoder 2024 -->
                    <h2 class="year">2024</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">TMLR 2024</abbr>
                                    <img src="../publications/images/combination-homomorphic-emg.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Fast and Expressive Gesture Recognition using a Combination-Homomorphic Electromyogram Encoder</div>
                                    <div class="author">
                                        <a href="https://nik-sm.github.io/" target="_blank" rel="noopener noreferrer">Niklas Smedemark-Margulies*</a>,
                                        <a href="https://www.linkedin.com/in/yunusbicer/" target="_blank" rel="noopener noreferrer">Yunus Bicer*</a>,
                                        <a href="https://www.linkedin.com/in/elifnursunger/" target="_blank" rel="noopener noreferrer">Elifnur Sunger</a>,
                                        <a href="https://coe.northeastern.edu/people/imbiriba-tales/" target="_blank" rel="noopener noreferrer">Tales Imbiriba</a>,
                                        <a href="https://bouve.northeastern.edu/directory/eugene-tunik/" target="_blank" rel="noopener noreferrer">Eugene Tunik</a>,
                                        <a href="https://web.northeastern.edu/deniz/" target="_blank" rel="noopener noreferrer">Deniz Erdogmus</a>,
                                        <a href="https://coe.northeastern.edu/people/yarossi-mathew/" target="_blank" rel="noopener noreferrer">Mathew Yarossi</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>
                                    </div>

                                    <div class="periodical">
                                        <em>Transactions on Machine Learning Research</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://openreview.net/pdf?id=j5T4pcLbcY" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://github.com/nik-sm/com-hom-emg" class="btn btn-sm z-depth-0" role="button">Code</a>
                                        <a href="https://zenodo.org/records/10359729" class="btn btn-sm z-depth-0" role="button">Dataset</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>
                                        We study the task of gesture recognition from electromyography (EMG), with the goal of enabling expressive human-computer interaction at high accuracy, while minimizing the time required for new subjects to provide calibration data.
                                        To fulfill these goals, we define combination gestures consisting of a direction component and a modifier component.
                                        New subjects only demonstrate the single component gestures and we seek to extrapolate from these to all possible single or combination gestures.
                                        We extrapolate to unseen combination gestures by combining the feature vectors of real single gestures to produce synthetic training data.
                                        This strategy allows us to provide a large and flexible gesture vocabulary, while not requiring new subjects to demonstrate combinatorially many example gestures.
                                        We pre-train an encoder and a combination operator using self-supervision, so that we can produce useful synthetic training data for unseen test subjects. 
                                        To evaluate the proposed method, we collect and release a real-world EMG dataset, and measure the effect of augmented supervision against two baselines: a partially-supervised model trained with only single gesture data from the unseen subject, and a fully-supervised model trained with real single and real combination gesture data from the unseen subject.
                                        We find that the proposed method provides a dramatic improvement over the partially-supervised model, and achieves a useful classification accuracy that in some cases approaches the performance of the fully-supervised model.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>


                    <!-- International Mathematics Research Notices, 2024(24):14543–14575, 2024. -->
                    <h2 class="year">2024</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">2024</abbr>
                                    <img src="../publications/images/FinkelbergGinzburgMirabolic.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">International Mathematics Research Notices, 2024(24):14543–14575, 2024.</div>
                                    <div class="author">
                                        <a href="" target="_blank" rel="noopener noreferrer"> Valerio Toledano Laredo*</a> &
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters*</a>, 
                                        On the finkelberg – ginzburg mirabolic monodromy conjecture.
                                    </div>

                                    <div class="periodical">
                                        <em>International Conference on Learning Representations (ICLR), Oral, 2024.</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://academic.oup.com/imrn/article-pdf/2024/24/14543/60669246/rnae245.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://academic.oup.com/imrn/article/2024/24/14543/7899440" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                        <!-- <a href="https://zenodo.org/records/10359729" class="btn btn-sm z-depth-0" role="button">Dataset</a> -->
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>
                                            We compute the monodromy of the mirabolic-module for all values of the parameters in rank 1 and outside an explicit codimension 2 set of values in ranks 2 and higher. This shows in particular that the Finkelberg–Ginzburg conjecture, which is known to hold for generic values of⁠, fails at special values even in rank 1. Our main tools are Opdam’s shift operators and intertwiners for the extended affine Weyl group, which allow for the resolution of resonances outside the codimension two set.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>




<!------------------------- 2 0 2 4 ------------------------->
<!---------------------ROGERS HOLLOW EDIT ------------------->





                    <!-- Haojie IJRR 2024 Leverage symmetries in pick and place  -->
                    <h2 class="year">2024</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">IJRR 2024</abbr>
                                    <img src="../publications/images/ijrr_lspp.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Leveraging Symmetries in Pick and Place</div>
                                    <div class="author">
                                        <a href="https://haojhuang.github.io/" target="_blank" rel="noopener noreferrer">Haojie Huang</a>,
                                        <a href="https://pointw.github.io/" target="_blank" rel="noopener noreferrer">Dian Wang</a>,
                                        <a href="https://www.linkedin.com/in/arsh-tangri-a71194195/" target="_blank" rel="noopener noreferrer">Arsh Tangri</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters*</a>
                                        <a href="https://helpinghandslab.netlify.app/people/" target="_blank" rel="noopener noreferrer">Robert Platt*</a>,
                                    </div>

                                    <div class="periodical">
                                        <em>The International Journal of Robotics Research, Volume 43, Issue 4, 2024</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2308.07948" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://haojhuang.github.io/etp_page/" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                        <a href="https://github.com/HaojHuang/Equivariant-Transporter-Net" class="btn btn-sm z-depth-0" role="button">Code</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>
                    

                    <h2 class="year">2023</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">NeurIPS 2023</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr> -->
                                    <!-- <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/hermes.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Modeling Dynamics over Meshes with Gauge Equivariant Nonlinear Message Passing</div>
                                    <div class="author">
                                        <a href="https://jypark0.github.io/" target="_blank" rel="noopener noreferrer">Jung Yeon Park</a>,
                                        <a href="https://www.khoury.northeastern.edu/home/lsw/" target="_blank" rel="noopener noreferrer">Lawson L.S. Wong</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>
                                    </div>

                                    <div class="periodical">
                                        <em>Conference on Neural Information Processing Systems 2023</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/abs/2310.19589" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://github.com/jypark0/hermes" class="btn btn-sm z-depth-0" role="button">Code</a>
                                        <a href="https://jypark0.github.io/hermes/" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: Data over non-Euclidean manifolds, often discretized as surface meshes, naturally arise in computer graphics and biological and physical systems. In particular, solutions to partial differential equations (PDEs) over manifolds depend critically on the underlying geometry. While graph neural networks have been successfully applied to PDEs, they do not incorporate surface geometry and do not consider local gauge symmetries of the manifold. Alternatively, recent works on gauge equivariant convolutional and attentional architectures on meshes leverage the underlying geometry but underperform in modeling surface PDEs with complex nonlinear dynamics. To address these issues, we introduce a new gauge equivariant architecture using nonlinear message passing. Our novel architecture achieves higher performance than either convolutional or attentional networks on domains with highly complex and nonlinear dynamics. However, similar to the non-mesh case, design trade-offs favor convolutional, attentional, or message passing networks for different tasks; we investigate in which circumstances our message passing method provides the most benefit.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2023</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">NeurIPS 2023</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr> -->
                                    <!-- <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/dian_neurips23.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">A General Theory of Correct, Incorrect, and Extrinsic Equivariance</div>
                                    <div class="author">
                                        <a href="https://pointw.github.io" target="_blank" rel="noopener noreferrer">Dian Wang</a>,
                                        <a href="https://zxp-s-works.github.io" target="_blank" rel="noopener noreferrer">Xupeng Zhu</a>,
                                        <a href="https://jypark0.github.io/" target="_blank" rel="noopener noreferrer">Jung Yeon Park</a>,
                                        <a href="https://saulbatman.github.io/" target="_blank" rel="noopener noreferrer">Mingxi Jia</a>,
                                        <a href="https://xxs90.github.io/" target="_blank" rel="noopener noreferrer">Guanang Su</a>,
                                        <a href="https://www.khoury.northeastern.edu/people/robert-platt/" target="_blank" rel="noopener noreferrer">Robert Platt</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>
                                    </div>

                                    <div class="periodical">
                                        <em>Conference on Neural Information Processing Systems 2023</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2303.04745.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://github.com/pointW/ext_theory" class="btn btn-sm z-depth-0" role="button">Code</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: Although equivariant machine learning has proven effective at many tasks, success depends heavily on the assumption that the ground truth function is symmetric over the entire domain matching the symmetry in an equivariant neural network. A missing piece in the equivariant learning literature is the analysis of equivariant networks when symmetry exists only partially in the domain. In this work, we present a general theory for such a situation. We propose pointwise definitions of correct, incorrect, and extrinsic equivariance, which allow us to quantify continu- ously the degree of each type of equivariance a function displays. We then study the impact of various degrees of incorrect or extrinsic symmetry on model error. We prove error lower bounds for invariant or equivariant networks in classification or regression settings with partially incorrect symmetry. We also analyze the poten- tially harmful effects of extrinsic equivariance. Experiments validate these results in three different environments.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2023</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">ICLR 2023</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr> -->
                                    <!-- <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/surprising-effectiveness.gif" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">The Surprising Effectiveness of Equivariant Models in Domains with Latent Symmetry</div>
                                    <div class="author">
                                        <a href="https://pointw.github.io" target="_blank" rel="noopener noreferrer">Dian Wang</a>,
                                        <a href="https://jypark0.github.io/" target="_blank" rel="noopener noreferrer">Jung Yeon Park</a>,
                                        <a href="#" target="_blank" rel="noopener noreferrer">Neel Sortur</a>,
                                        <a href="https://www.khoury.northeastern.edu/home/lsw/" target="_blank" rel="noopener noreferrer">Lawson L.S. Wong</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters*</a>,
                                        <a href="https://www.khoury.northeastern.edu/people/robert-platt/" target="_blank" rel="noopener noreferrer">Robert Platt*</a>
                                    </div>

                                    <div class="periodical">
                                        <em>International Conference on Learning Representations 2023</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2211.09231.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <!-- <a href="https://github.com/pointW/equi_rl" class="btn btn-sm z-depth-0" role="button">Code</a> -->
                                        <a href="https://pointw.github.io/extrinsic_page/" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: Extensive work has demonstrated that equivariant neural networks can significantly improve sample efficiency and generalization by enforcing an inductive bias in the network architecture. These applications
                                            typically assume that the domain symmetry is fully described by explicit transformations of the model inputs and outputs. However, many real-life applications contain only latent or partial symmetries which
                                            cannot be easily described by simple transformations of the input. In these cases, it is necessary to learn symmetry in the environment instead of imposing it mathematically on the network architecture. We discover,
                                            surprisingly, that imposing equivariance constraints that do not exactly match the domain symmetry is very helpful in learning the true symmetry in the environment. We differentiate between extrinsic and incorrect
                                            symmetry constraints and show that while imposing incorrect symmetry can impede the model's performance, imposing extrinsic symmetry can actually improve performance. We demonstrate that an equivariant model
                                            can significantly outperform non-equivariant methods on domains with latent symmetries both in supervised learning and in reinforcement learning for robotic manipulation and control problems.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2023</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">ICRA 2023</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr> -->
                                    <!-- <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/seil.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">SEIL: Simulation-augmented Equivariant Imitation Learning</div>
                                    <div class="author">
                                        <a href="https://saulbatman.github.io/" target="_blank" rel="noopener noreferrer">Mingxi Jia*</a>,
                                        <a href="https://pointw.github.io" target="_blank" rel="noopener noreferrer">Dian Wang*</a>,
                                        <a href="https://xxs90.github.io/" target="_blank" rel="noopener noreferrer">Guanang Su</a>,
                                        <a href="https://dmklee.github.io/" target="_blank" rel="noopener noreferrer">David Klee</a>,
                                        <a href="https://zxp-s-works.github.io/" target="_blank" rel="noopener noreferrer">Xupeng Zhu</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>,
                                        <a href="https://www.khoury.northeastern.edu/people/robert-platt/" target="_blank" rel="noopener noreferrer">Robert Platt</a>
                                    </div>

                                    <div class="periodical">
                                        <em>International Conference on Robotics and Automation 2023</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2211.00194.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <!-- <a href="https://github.com/pointW/equi_rl" class="btn btn-sm z-depth-0" role="button">Code</a> -->
                                        <a href="https://saulbatman.github.io/project/seil/" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: In robotic manipulation, acquiring samples is extremely expensive because it often requires interacting with the real world. Traditional image-level data augmentation has shown the potential to improve
                                            sample efficiency in various machine learning tasks. However, image-level data augmentation is insufficient for an imitation learning agent to learn good manipulation policies in a reasonable amount of demonstrations.
                                            We propose Simulation-augmented Equivariant Imitation Learning (SEIL), a method that combines a novel data augmentation strategy of supplementing expert trajectories with simulated transitions and an equivariant
                                            model that exploits the O(2) symmetry in robotic manipulation. Experimental evaluations demonstrate that our method can learn non-trivial manipulation tasks within ten demonstrations and outperforms the baselines
                                            with a significant margin.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2023</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">ICRA 2022</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr> -->
                                    <!-- <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/Edge-grasp-networks.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Edge Grasp Network: Graph-Based SE(3)-invariant Approach to Grasp Detection</div>
                                    <div class="author">
                                        <a href="https://haojhuang.github.io/" target="_blank" rel="noopener noreferrer">Haojie Huang</a>,
                                        <a href="https://pointw.github.io" target="_blank" rel="noopener noreferrer">Dian Wang</a>,
                                        <a href="https://zxp-s-works.github.io/" target="_blank" rel="noopener noreferrer">Xupend Zhu</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>,
                                        <a href="https://www.khoury.northeastern.edu/people/robert-platt/" target="_blank" rel="noopener noreferrer">Robert Platt</a>
                                    </div>

                                    <div class="periodical">
                                        <em>International Conference on Robotics and Automation 2023</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2211.00191.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <!-- <a href="https://github.com/HaojHuang/Equivariant-Transporter-Net" class="btn btn-sm z-depth-0" role="button">Code</a> -->
                                        <a href="https://haojhuang.github.io/edge_grasp_page/" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: Given point cloud input, the problem of 6-DoF grasp pose detection is to identify a set of hand poses in SE(3) from which an object can be successfully grasped. This important problem has many practical
                                            applications. Here we propose a novel method and neural network model that enables better grasp success rates relative to what is available in the literature. The method takes standard point cloud data as input
                                            and works well with single-view point clouds observed from arbitrary viewing directions.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2022</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">ICML 2022</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr> -->
                                    <!-- <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/sen.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Learning Symmetric Embedding Networks for Equivariant World Models</div>
                                    <div class="author">
                                        <a href="https://jypark0.github.io/" target="_blank" rel="noopener noreferrer">Jung Yeon Park</a>,
                                        <a href="https://sites.google.com/view/obiza" target="_blank" rel="noopener noreferrer">Ondrej Biza</a>,
                                        <a href="https://lfzhao.com/" target="_blank" rel="noopener noreferrer">Linfeng Zhao</a>,
                                        <a href="https://jwvdm.github.io/" target="_blank" rel="noopener noreferrer">Jan-Willem van de Meent</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>
                                    </div>

                                    <div class="periodical">
                                        <em>We propose learning symmetric embedding networks (SENs) for input spaces where we do not know the effects of symmetry transformations, to a feature space where the transformation is known. This network can be combined with downstream task-specific equivariant networks and trained end-to-end in latent space. SENs can extend the applicability of equivariant networks to a wider variety of domains.</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/abs/2204.11371" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <!-- <a href="https://github.com/pointW/equi_rl" class="btn btn-sm z-depth-0" role="button">Code</a> -->
                                        <a href="https://github.com/jypark0/sen" class="btn btn-sm z-depth-0" role="button">Code</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: Incorporating symmetries can lead to highly data-efficient and generalizable models by defining equivalence classes of data samples related by transformations. However, characterizing how transformations
                                            act on input data is often difficult, limiting the applicability of equivariant models. We propose learning symmetric embedding networks (SENs) that encode an input space (e.g. images), where we do not know
                                            the effect of transformations (e.g. rotations), to a feature space that transforms in a known manner under these operations. This network can be trained end-to-end with an equivariant task network to learn an
                                            explicitly symmetric representation. We validate this approach in the context of equivariant transition models with 3 distinct forms of symmetry. Our experiments demonstrate that SENs facilitate the application
                                            of equivariant networks to data with complex symmetry representations. Moreover, doing so can yield improvements in accuracy and generalization relative to both fully-equivariant and non-equivariant baselines.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2022</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">PMLR Vol. 197</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr>
                                    <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/image-to-icosahedral.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Image to Icosahedral Projection for SO(3) Object Reasoning from Single-View Images</div>
                                    <div class="author">
                                        <a href="https://dmklee.github.io/" target="_blank" rel="noopener noreferrer">David M. Klee</a>,
                                        <a href="https://sites.google.com/view/obiza" target="_blank" rel="noopener noreferrer">Ondrej Biza</a>,
                                        <a href="https://www.khoury.northeastern.edu/people/robert-platt/" target="_blank" rel="noopener noreferrer">Robert Platt</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>
                                    </div>

                                    <div class="periodical">
                                        <em>We develop a hybrid equivariant model that incorporates SO(2) and SO(3) equivariant convolution layers to improve 3D reasoning from 2D images.   Our method outperforms baselines on shape classification and pose prediction tasks, especially in the low-data regime.</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/abs/2207.08925" target="_blank" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://github.com/dmklee/image2icosahedral" target="_blank" class="btn btn-sm z-depth-0" role="button">Code</a>
                                        <a href="https://dmklee.github.io/image2icosahedral/" target="_blank" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: Reasoning about 3D objects based on 2D images is challenging due to variations in appearance caused by viewing the object from different orientations. Tasks such as object classification are invariant
                                            to 3D rotations and other such as pose estimation are equivariant. However, imposing equivariance as a model constraint is typically not possible with 2D image input because we do not have an a priori model
                                            of how the image changes under out-of-plane object rotations. The only SO(3)-equivariant models that currently exist require point cloud or voxel input rather than 2D images. In this paper, we propose a novel
                                            architecture based on icosahedral group convolutions that reasons in SO(3) by learning a projection of the input image onto an icosahedron. The resulting model is approximately equivariant to rotation in SO(3).
                                            We apply this model to object pose estimation and shape classification tasks and find that it outperforms reasonable baselines.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2022</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">RLDM 2022</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr>
                                    <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/understanding-the-mechanisms.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Understanding the Mechanism behind Data Augmentation's Success on Image-based RL
                                    </div>
                                    <div class="author">
                                        <a href="https://dmklee.github.io/" target="_blank" rel="noopener noreferrer">David M. Klee</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>,
                                        <a href="https://www.khoury.northeastern.edu/people/robert-platt/" target="_blank" rel="noopener noreferrer">Robert Platt</a>
                                    </div>

                                    <div class="periodical">
                                        <em>Data augmentation is known to provide substantial benefits for image-based reinforcement learning (RL) but the mechanism is not clear.  We show that data augmentation increases both the equivariance and invariance of the convolutional encoder, e.g. the feature map is spatially smooth.  We show that a simple Gaussian blur operation can achieve the same effect for some of the tested environments.</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://dmklee.github.io/assets/publications/data_aug/paper.pdf" target="_blank" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://dmklee.github.io/assets/publications/data_aug/poster.pdf" target="_blank" class="btn btn-sm z-depth-0" role="button">Poster</a>
                                        <!-- <a href="https://dmklee.github.io/image2icosahedral/" target="_blank" class="btn btn-sm z-depth-0" role="button">Webpage</a> -->
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: Reinforcement learning for continuous control tasks is challenging with image observations, due to the representation learning problem. A series of recent work has shown that augmenting the observations
                                            via random shifts during training significantly improves performance, even matching state-based methods. However, it is not well-understood why augmentation is so beneficial; since the method uses a nearly-shift
                                            equivariant convolutional encoder, shifting the input should have little impact on what features are learned. In this work, we investigate why random shifts are useful augmentations for image-based RL and show
                                            that it increases both the shift-equivariance and shift-invariance of the encoder. In other words, the visual features learned exhibit spatial continuity, which we show can be partially achieved using dropout.
                                            We hypothesize that the spatial continuity of the visual encoding simplifies learning for the subsequent linear layers in the actor-critic networks.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2022</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <!-- <abbr class="badge">ICML</abbr> -->
                                    <abbr class="badge">ICLR 2022</abbr>
                                    <!-- <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/SO(2)-Equivariant-Reinforcement-Learning.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">SO(2)-Equivariant Reinforcement Learning</div>
                                    <div class="author">
                                        <a href="https://pointw.github.io" target="_blank" rel="noopener noreferrer">Dian Wang</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>,
                                        <a href="https://www.khoury.northeastern.edu/people/robert-platt/" target="_blank" rel="noopener noreferrer">Robert Platt</a>
                                    </div>

                                    <div class="periodical">
                                        <em>International Conference on Learning Representations 2022</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2203.04439.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://github.com/pointW/equi_rl" class="btn btn-sm z-depth-0" role="button">Code</a>
                                        <a href="https://pointw.github.io/equi_rl_page/" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: Equivariant neural networks enforce symmetry within the structure of their convolutional layers, resulting in a substantial improvement in sample efficiency when learning an equivariant or invariant function.
                                            Such models are applicable to robotic manipulation learning which can often be formulated as a rotationally symmetric problem. This paper studies equivariant model architectures in the context of Q-learning
                                            and actor-critic reinforcement learning. We identify equivariant and invariant characteristics of the optimal Q-function and the optimal policy and propose equivariant DQN and SAC algorithms that leverage this
                                            structure. We present experiments that demonstrate that our equivariant versions of DQN and SAC can be significantly more sample efficient than competing algorithms on an important class of robotic manipulation
                                            problems.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2022</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">RSS 2022</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr> -->
                                    <!-- <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/equi_transporter.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Equivariant Transporter Network</div>
                                    <div class="author">
                                        <a href="https://haojhuang.github.io/" target="_blank" rel="noopener noreferrer">Haojie Huang</a>,
                                        <a href="https://pointw.github.io" target="_blank" rel="noopener noreferrer">Dian Wang</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>,
                                        <a href="https://www.khoury.northeastern.edu/people/robert-platt/" target="_blank" rel="noopener noreferrer">Robert Platt</a>
                                    </div>

                                    <div class="periodical">
                                        <em>Robotics: Science and Systems 2022</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2202.09400.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://github.com/HaojHuang/Equivariant-Transporter-Net" class="btn btn-sm z-depth-0" role="button">Code</a>
                                        <a href="https://haojhuang.github.io/etp_page/" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: Transporter Net is a recently proposed framework for pick and place that is able to learn good manipulation policies from a very few expert demonstrations [35]. A key reason why Transporter Net is so sample
                                            efficient is that the model incorporates rotational equivariance into the pick-conditioned place module, i.e. the model immediately generalizes learned pick-place knowledge to objects presented in different
                                            pick orientations. This paper proposes a novel version of Transporter Net that is equivariant to both pick and place orientation. As a result, our model immediately generalizes pick-place knowledge to different
                                            place orientations in addition to generalizing the pick orientation as before. Ultimately, our new model is more sample efficient and achieves better pick and place success rates than the baseline Transporter
                                            Net model.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2022</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">CoRL 2022</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr> -->
                                    <!-- <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/On-Robot-Learning-With-Equivariant-Models.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">On-Robot Learning With Equivariant Models</div>
                                    <div class="author">
                                        <a href="https://pointw.github.io" target="_blank" rel="noopener noreferrer">Dian Wang</a>,
                                        <a href="https://saulbatman.github.io/" target="_blank" rel="noopener noreferrer">Mingxi Jia</a>,
                                        <a href="https://zxp-s-works.github.io/" target="_blank" rel="noopener noreferrer">Xupeng Zhu</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>,
                                        <a href="https://www.khoury.northeastern.edu/people/robert-platt/" target="_blank" rel="noopener noreferrer">Robert Platt</a>
                                    </div>

                                    <div class="periodical">
                                        <em>Conference on Robot Learning 2022</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2203.04923.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://github.com/pointW/equi_rl" class="btn btn-sm z-depth-0" role="button">Code</a>
                                        <a href="https://pointw.github.io/equi_robot_page/" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: Recently, equivariant neural network models have been shown to improve sample efficiency for tasks in computer vision and reinforcement learning. This paper explores this idea in the context of on-robot
                                            policy learning in which a policy must be learned entirely on a physical robotic system without reference to a model, a simulator, or an offline dataset. We focus on applications of Equivariant SAC to robotic
                                            manipulation and explore a number of variations of the algorithm. Ultimately, we demonstrate the ability to learn several non-trivial manipulation tasks completely through on-robot experiences in less than an
                                            hour or two of wall clock time.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2021</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">CoRL 2021</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr> -->
                                    <!-- <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/Equivariant-Q-Learning-in-Spatial-Action-Spaces.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Equivariant Q Learning in Spatial Action Spaces</div>
                                    <div class="author">
                                        <a href="https://pointw.github.io" target="_blank" rel="noopener noreferrer">Dian Wang</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>,
                                        <a href="https://zxp-s-works.github.io/" target="_blank" rel="noopener noreferrer">Xupeng Zhu</a>,
                                        <a href="https://www.khoury.northeastern.edu/people/robert-platt/" target="_blank" rel="noopener noreferrer">Robert Platt</a>
                                    </div>

                                    <div class="periodical">
                                        <em>Conference on Robot Learning 2021</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2110.15443.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://github.com/pointW/equi_q_corl21" class="btn btn-sm z-depth-0" role="button">Code</a>
                                        <a href="https://pointw.github.io/equi_q_page/" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: Recently, a variety of new equivariant neural network model architectures have been proposed that generalize better over rotational and reflectional symmetries than standard models. These models are relevant
                                            to robotics because many robotics problems can be expressed in a rotationally symmetric way. This paper focuses on equivariance over a visual state space and a spatial action space - the setting where the robot
                                            action space includes a subset of SE(2). In this situation, we know a priori that rotations and translations in the state image should result in the same rotations and translations in the spatial action dimensions
                                            of the optimal policy. Therefore, we can use equivariant model architectures to make Q learning more sample efficient. This paper identifies when the optimal Q function is equivariant and proposes Q network
                                            architectures for this setting. We show experimentally that this approach outperforms standard methods in a set of challenging manipulation problems.

                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

            </article>

            </div>

        </div>

        <!-- Footer -->


        <footer class="sticky-bottom mt-5 ">
            <div class="container ">
                Made with <a href="http://jekyllrb.com/ " target="_blank " rel="noopener noreferrer ">Jekyll</a> and Bootstrap.
            </div>
        </footer>

</body>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

<!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>

<!-- Enable Tooltips -->
<script type="text/javascript">
    $(function() {
        $('[data-toggle="tooltip"]').tooltip()
    })
</script>

<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- MathJax -->
<script type="text/javascript">
    window.MathJax = {
        tex: {
            tags: 'ams'
        }
    };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-185703812-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
        dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'UA-185703812-1');
</script>

<script>
    $(document).ready(function() {
        $('a.abstract').click(function() {
            $(this).parent().parent().find(".abstract.hidden").toggleClass('open');
        });
        $('a.bibtex').click(function() {
            $(this).parent().parent().find(".bibtex.hidden").toggleClass('open');
        });
        $('.navbar-nav').find('a').removeClass('waves-effect waves-light');
    });
</script>


<!-- COLLAPSIBLE PUBLICATIONS -->
 <script>

var coll = document.getElementsByClassName("collapsible");
var i;

for (i = 0; i < coll.length; i++) {
  coll[i].addEventListener("click", function() {
    this.classList.toggle("active");
    var content = this.nextElementSibling;
    if (content.style.maxHeight){
      content.style.maxHeight = null;
    } else {
      content.style.maxHeight = content.scrollHeight + "px";
    }
  });
}
</script>

</html>
